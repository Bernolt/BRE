{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Recommendation Engines in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/movielens.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart\n",
    "\n",
    "![](images/light_fm.png)\n",
    "\n",
    "[Source](https://github.com/lyst/lightfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install lightfm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050462354"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "data = fetch_movielens(min_rating=5.0)\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(data['train'], epochs=30, num_threads=2)\n",
    "\n",
    "precision_at_k(model, data['test'], k=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 19048 stored elements in COOrdinate format>,\n",
       " 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 2153 stored elements in COOrdinate format>,\n",
       " 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1682 stored elements in Compressed Sparse Row format>,\n",
       " 'item_feature_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
       " 'item_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 19048 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/candy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/influenster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15611</td>\n",
       "      <td>Reese's White Peanut Butter Eggs</td>\n",
       "      <td>victorkelly</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2191</td>\n",
       "      <td>Skittles Sour Candy</td>\n",
       "      <td>kim99</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>Airheads White Mystery</td>\n",
       "      <td>jeffrey15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9915</td>\n",
       "      <td>Life Savers Holiday Wint-O-Green Candy Mints</td>\n",
       "      <td>julieconway</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12048</td>\n",
       "      <td>Nestle Toll House Semi Sweet Chocolate Morsels</td>\n",
       "      <td>travis02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 item         user  review\n",
       "15611                Reese's White Peanut Butter Eggs  victorkelly       5\n",
       "2191                              Skittles Sour Candy        kim99       5\n",
       "7350                           Airheads White Mystery    jeffrey15       5\n",
       "9915     Life Savers Holiday Wint-O-Green Candy Mints  julieconway       5\n",
       "12048  Nestle Toll House Semi Sweet Chocolate Morsels     travis02       5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/candy.csv')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2186</td>\n",
       "      <td>Skittles Sour Candy</td>\n",
       "      <td>zjohnson</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6022</td>\n",
       "      <td>Haribo Sour Gold Bears Gummi Candy</td>\n",
       "      <td>zjohnson</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7919</td>\n",
       "      <td>Starburst Original Fruit Chews</td>\n",
       "      <td>zjohnson</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8382</td>\n",
       "      <td>Sour Patch Watermelon</td>\n",
       "      <td>zjohnson</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12304</td>\n",
       "      <td>Sour Patch Kids Candy</td>\n",
       "      <td>zjohnson</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     item      user  review\n",
       "2186                  Skittles Sour Candy  zjohnson       5\n",
       "6022   Haribo Sour Gold Bears Gummi Candy  zjohnson       5\n",
       "7919       Starburst Original Fruit Chews  zjohnson       5\n",
       "8382                Sour Patch Watermelon  zjohnson       5\n",
       "12304               Sour Patch Kids Candy  zjohnson       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['user'] == 'zjohnson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Twix                                       340\n",
       "Snickers Chocolate Bar                     330\n",
       "Werther's Original Caramel Hard Candies    322\n",
       "M&Ms Peanut Chocolate Candy                310\n",
       "M&Ms Milk Chocolate Candy                  273\n",
       "Name: item, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['item'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['item'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2531,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    12977\n",
       "4     2554\n",
       "3      967\n",
       "2      372\n",
       "1      364\n",
       "Name: review, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.809166337416041"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user')['item'].count().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twix</th>\n",
       "      <th>mars</th>\n",
       "      <th>reeses</th>\n",
       "      <th>skittles</th>\n",
       "      <th>snickers</th>\n",
       "      <th>lindt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   twix  mars  reeses  skittles  snickers  lindt\n",
       "0     0     1       1         0         0      0\n",
       "1     0     1       1         1         0      0\n",
       "2     1     0       0         1         0      0\n",
       "3     0     1       1         0         0      1\n",
       "4     0     0       0         1         1      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = pd.DataFrame([\n",
    "    [0, 1, 1, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [0, 1, 1, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 1, 1]], \n",
    "    columns=['twix', 'mars', 'reeses', 'skittles', 'snickers', 'lindt'])\n",
    "\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43333333333333335"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, c = ex.shape\n",
    "ex.sum().sum() / (r * c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.getsizeof(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "sx = csc_matrix(ex.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(sx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Candy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = 'review'\n",
    "users = 'user'\n",
    "items = 'item'\n",
    "\n",
    "ratings = np.array(df[ratings])\n",
    "users = np.array(df[users])\n",
    "items = np.array(df[items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "help(csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "csr_matrix((data, (row, col)), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# heavy lifting encoders\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# preparation for the csr matrix\n",
    "u = user_encoder.fit_transform(users)\n",
    "i = item_encoder.fit_transform(items)\n",
    "lu = len(np.unique(u))\n",
    "li = len(np.unique(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = csr_matrix((ratings, (u, i)), shape=(lu, li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionMachine:\n",
    "    def __init__(self):\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        self.item_encoder = LabelEncoder()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'InteractionMachine()'\n",
    "\n",
    "    def build(self, users, items, ratings):\n",
    "        u = self.user_encoder.fit_transform(users)\n",
    "        i = self.item_encoder.fit_transform(items)\n",
    "        self.n_users = len(np.unique(u))\n",
    "        self.n_items = len(np.unique(i))\n",
    "        self.interactions = csr_matrix((ratings, (u, i)), shape=(self.n_users, self.n_items))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = InteractionMachine()\n",
    "\n",
    "im.build(df['user'], df['item'], df['review'])\n",
    "\n",
    "interactions = im.interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic LightFM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(interactions) # not exactly sklearn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(0, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score, precision_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AUC measures the quality of the overall ranking. In the binary case, it can be interpreted as the probability that a randomly chosen positive item is ranked higher than a randomly chosen negative item. Consequently, an AUC close to 1.0 will suggest that, by and large, your ordering is correct: and this can be true even if none of the first K items are positives. This metric may be more appropriate if you do not exert full control on which results will be presented to the user; it may be that the first K recommended items are not available any more (say, they are out of stock), and you need to move further down the ranking. A high AUC score will then give you confidence that your ranking is of high quality throughout.\n",
    "\n",
    "[Source](https://stackoverflow.com/questions/45451161/evaluating-the-lightfm-recommendation-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Precision@K measures the proportion of positive items among the K highest-ranked items. As such, it's very focused on the ranking quality at the top of the list: it doesn't matter how good or bad the rest of your ranking is as long as the first K items are mostly positive. This would be an appropriate metric if you are only ever going to be showing your users the very top of the list.\n",
    "\n",
    "[Source](https://stackoverflow.com/questions/45451161/evaluating-the-lightfm-recommendation-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score(model, interactions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_k(model, interactions, k=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't do this...\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split(interactions)\n",
    "# because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional \n",
    "\n",
    "![](images/tts_traditional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation\n",
    "\n",
    "![](images/tts_reco.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this\n",
    "from lightfm.cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_train_test_split(interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM()\n",
    "model.fit(train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score(model, test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM()\n",
    "\n",
    "scores = []\n",
    "for e in range(100):\n",
    "    model.fit_partial(train, epochs=1)\n",
    "    auc_train = auc_score(model, train).mean()\n",
    "    auc_test = auc_score(model, test).mean()\n",
    "    scores.append((auc_train, auc_test))\n",
    "    \n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(scores[:, 0], label='train')\n",
    "plt.plot(scores[:, 1], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> WARP: Weighted Approximate-Rank Pairwise loss. Maximises\n",
    "  the rank of positive examples by repeatedly sampling negative\n",
    "  examples until rank violating one is found. Useful when only\n",
    "  positive interactions are present and optimising the top of\n",
    "  the recommendation list (precision@k) is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(loss='warp')\n",
    "\n",
    "scores = []\n",
    "for e in range(100):\n",
    "    model.fit_partial(train, epochs=1)\n",
    "    auc_train = auc_score(model, train).mean()\n",
    "    auc_test = auc_score(model, test).mean()\n",
    "    scores.append((auc_train, auc_test))\n",
    "    \n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(scores[:, 0], label='train')\n",
    "plt.plot(scores[:, 1], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity\n",
    "\n",
    "Take 5 minutes to explore different epoch and loss combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "model = LightFM(loss='warp')\n",
    "\n",
    "count = 0\n",
    "best = 0\n",
    "scores = []\n",
    "for e in range(100):\n",
    "    if count > 5: # patience\n",
    "        break\n",
    "    model.fit_partial(train, epochs=1)\n",
    "    auc_train = auc_score(model, train).mean()\n",
    "    auc_test = auc_score(model, test).mean()\n",
    "    print(f'Epoch: {e}, Train AUC={auc_train:.3f}, Test AUC={auc_test:.3f}')\n",
    "    scores.append((auc_train, auc_test))\n",
    "    if auc_test > best:\n",
    "        best_model = deepcopy(model)\n",
    "        best = auc_test\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "model = deepcopy(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'aaron67'\n",
    "df[df['user'] == user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.user_encoder.transform([user])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = im.user_encoder.transform([user])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(user_id, list(range(im.n_items)))\n",
    "preds = pd.DataFrame(zip(preds, im.item_encoder.classes_), columns=['pred', 'item'])\n",
    "preds = preds.sort_values('pred', ascending=False)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tried = df[df['user'] == user]['item'].values\n",
    "list(preds[~preds['item'].isin(tried)]['item'].values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/willy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unless..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.DataFrame([\n",
    "    [0, 1, 1, 0, 0, 0], \n",
    "    [0, 1, 1, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [0, 1, 1, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "euclidean_distances(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/candy.csv\")\n",
    "df = df[df['review'] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"user\"])[\"item\"].apply(lambda x: \",\".join(x))\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=lambda x: x.split(\",\"), max_features=250)\n",
    "X = cv.fit_transform(df['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5)\n",
    "nn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = nn.kneighbors(X, return_distance=False)\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candy = []\n",
    "for n in neighbors[0]:\n",
    "    c = df.iloc[int(n)].values[0].split(\",\")\n",
    "    candy.extend(c)\n",
    "    \n",
    "list(set(candy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting a bow on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/candy.csv\")\n",
    "df = df[df['review'] >= 4]\n",
    "df = df.groupby([\"user\"])[\"item\"].apply(lambda x: \",\".join(x))\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNRecommender:\n",
    "    def __init__(\n",
    "        self, n_neighbors=5, max_features=250, tokenizer=lambda x: x.split(\",\")):\n",
    "        self.cv = CountVectorizer(tokenizer=tokenizer, max_features=max_features)\n",
    "        self.nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        X = self.cv.fit_transform(X)\n",
    "        self.nn.fit(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xp = []\n",
    "        for Xi in X:\n",
    "            Xt = self.cv.transform([Xi])\n",
    "            neighbors = self.nn.kneighbors(Xt, return_distance=False)\n",
    "            repos = []\n",
    "            for n in neighbors[0]:\n",
    "                r = self.X.iloc[int(n)].split(\",\")\n",
    "                repos.extend(r)\n",
    "            repos = list(set(repos))\n",
    "            repos = [r for r in repos if r not in Xi.split(\",\")]\n",
    "            Xp.append(repos)\n",
    "        return Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 5\n",
    "max_features = 250\n",
    "model = NNRecommender(n_neighbors, max_features)\n",
    "model.fit(df[\"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)['item'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweet = [\"Airheads Xtremes Sweetly Sour Candy Rainbow Berry,Life Savers Five Flavor Gummies,Twizzlers Pull-N-Peel Candy Cherry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peanut = [\"Reese's Peanut Butter Cups Miniatures,M&Ms Peanut Chocolate Candy,Reese's Peanut Butter Big Cup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.item_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(sweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(peanut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/the_end.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max Humber** \n",
    "\n",
    "- [Twitter](https://twitter.com/maxhumber)\n",
    "- [LinkedIn](https://www.linkedin.com/in/maxhumber/)\n",
    "- [GitHub](https://github.com/maxhumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open Source**\n",
    "\n",
    "- [marc](https://github.com/maxhumber/marc) - (**mar**kov **c**hain) is a small, but flexible Markov chain generator.\n",
    "- [gazpacho](https://github.com/maxhumber/gazpacho) - is a web scraping library. You should use it!\n",
    "- [mummify](https://github.com/maxhumber/mummify) - makes model prototyping faster. \n",
    "- [chart](https://github.com/maxhumber/chart) - a zero-dependency python package that prints basic charts to a Jupyter output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [recommend](https://github.com/maxhumber/recommend) - basically this presentation (super beta right now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upcoming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For when your data looks like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/candy.csv')\n",
    "df = df[df['user'].isin(df['user'].sample(10))]\n",
    "df = df.pivot(index='item', columns='user', values='review')\n",
    "df = df.reset_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.melt(id_vars='item', var_name='user', value_name='review')\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parting Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/savage.png)\n",
    "\n",
    "[Source](https://news.ycombinator.com/item?id=20495047)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
